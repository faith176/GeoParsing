{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqMAGbzWZJ_v"
      },
      "source": [
        "# **Geoparsing: Prediction Evaluation**\n",
        "---\n",
        "**Prepared by**: Feyi Adesanya\n",
        "\n",
        "**Submission Date**: April 30, 2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import textwrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\FeyiA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from Pre.Preprocess import Preprocess\n",
        "from ML.CRF_Manager import CRF_Manager\n",
        "from Gaz.Gazetteer import Gazetteer\n",
        "from ML.Baseline_Manager import Baseline_Manager\n",
        "from ML.BI_LSTM_Manager import BI_LSTM_Manager\n",
        "from ML.SVM_Manager import SVM_Manager\n",
        "from ML.BERT_Manager import BERT_Manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieving Locations Array from Saved Data\n",
            "Corpus has 133639 Locations\n",
            "Retrieving BK Tree from Saved Data\n"
          ]
        }
      ],
      "source": [
        "gaz = Gazetteer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieving Corpus from Saved Data\n",
            "Corpus has 588 documents\n"
          ]
        }
      ],
      "source": [
        "preprocess = Preprocess(gaz)\n",
        "preprocess.extract_train_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Corpus Entry\n",
            "--------------------------------------------------\n",
            "Text: Alexandria woman charged in connection with Kelleyland fire. Chiquita Raquel Henry, 19, of 1935 Orchard St., Alexandria,\n",
            "was arrested and charged with aggravated arson and unauthorized entry of an inhabited dwelling. Both the Sheriff’s\n",
            "Office and Rapides Parish Fire District 2 investigated the March 7 fire at 6016 Dublin Road that led to Henry’s arrest.\n",
            "According to the Sheriff’s Office, the man who lives in the mobile home at that address was inside the home when Henry\n",
            "came in and set the bed and couch on fire with a lighter. The man only knew the woman by a nickname but investigation\n",
            "led detectives to Henry.\n",
            "\n",
            "Toponyms: [{'phrase': 'Alexandria', 'start': '0', 'end': '10', 'geonameid': 4314550, 'name': 'Alexandria', 'fclass': 'P', 'fcode': 'PPL', 'lat': 31.3113, 'lon': -92.4451, 'country': 'United States', 'admin1': 'Louisiana'}, {'phrase': 'Alexandria', 'start': '109', 'end': '119', 'geonameid': 4314550, 'name': 'Alexandria', 'fclass': 'P', 'fcode': 'PPL', 'lat': 31.3113, 'lon': -92.4451, 'country': 'United States', 'admin1': 'Louisiana'}, {'phrase': 'Rapides Parish', 'start': '247', 'end': '261', 'geonameid': 4338356, 'name': 'Rapides Parish', 'fclass': 'A', 'fcode': 'ADM2', 'lat': 31.1669, 'lon': -92.4835, 'country': 'United States', 'admin1': 'Louisiana'}]\n",
            "GeoNames IDs: [4314550, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 4314550, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 4338356, 4338356, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
            "Labels: ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Features: {'word_index': 3, 'doc_index': 0, 'start_index': 25, 'word.len': 2, 'has_internal_punctuations': 0, 'BOS': 0, 'EOS': 0, 'word': 'in', 'word_shape': 'a', 'word.lemma': 'in', 'pos_tag': 'ADP', 'Is_Preposition': 1, '-1:pos_tag': 'VERB', '+1:pos_tag': 'NOUN', '-1:word_shape': 'a', '+1:word_shape': 'a', '-1:word': 'charged', '+1:word': 'connection', '-1:has_internal_punctuations': 0, '+1:has_internal_punctuations': 0, '-1:Is_Preposition': 0, '+1:Is_Preposition': 0, 'IsLOCGaz': 0}...........\n"
          ]
        }
      ],
      "source": [
        "print(\"Sample Corpus Entry\")\n",
        "print(\"-\"*50)\n",
        "print(\"Text: \", end=\"\")\n",
        "print(textwrap.fill(preprocess.corpus[0]['text'], width=120))\n",
        "print()\n",
        "print(f\"Toponyms: {preprocess.corpus[0]['toponyms']}\")\n",
        "print(f\"GeoNames IDs: {preprocess.corpus[0]['geoIDs']}\")\n",
        "print(f\"Labels: {preprocess.corpus[0]['labels']}\")\n",
        "print(f\"Features: {preprocess.corpus[0]['features'][3]}...........\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prediction Model Results Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Base Scores\n",
            "Accuracy: 0.8113634283067943\n",
            "Precision: 0.9581236525580117\n",
            "Recall: 0.8113634283067943\n",
            "F1 Score: 0.8716944829103495\n",
            "--------------------------------------------------\n",
            "Relevant Scores: Labels of Interest: B-LOC and I-LOC\n",
            "Accuracy: 0.6012752075919335\n",
            "Precision: 0.9418148305098311\n",
            "Recall: 0.6012752075919335\n",
            "F1 Score: 0.732003186515096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\FeyiA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.09      0.63      0.16      4980\n",
            "       I-LOC       0.82      0.51      0.63      1764\n",
            "           O       0.98      0.82      0.89    178957\n",
            "\n",
            "    accuracy                           0.81    185701\n",
            "   macro avg       0.63      0.66      0.56    185701\n",
            "weighted avg       0.96      0.81      0.87    185701\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_baseline = Baseline_Manager(gaz, preprocess)\n",
        "test_baseline.predict_corpus()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['toronto', 'be', 'to', 'calgary']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"I'm leaving for Toronto tomorrow, I'll be sure to go into Calgary too\"\n",
        "test_baseline.new_prediction(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CRF Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weights loaded successfully.\n",
            "--------------------------------------------------\n",
            "Base Scores\n",
            "Accuracy: 0.9888516011603435\n",
            "Precision: 0.9882925795120062\n",
            "Recall: 0.9888516011603435\n",
            "F1 Score: 0.9882769035825909\n",
            "--------------------------------------------------\n",
            "Relevant Scores: Labels of Interest: B-LOC and I-LOC\n",
            "Accuracy: 0.7364864864864865\n",
            "Precision: 0.9839289947842579\n",
            "Recall: 0.7364864864864865\n",
            "F1 Score: 0.8422852691145374\n",
            "--------------------------------------------------\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.91      0.75      0.82       425\n",
            "       I-LOC       0.88      0.69      0.78       167\n",
            "           O       0.99      1.00      0.99     16989\n",
            "\n",
            "    accuracy                           0.99     17581\n",
            "   macro avg       0.93      0.82      0.87     17581\n",
            "weighted avg       0.99      0.99      0.99     17581\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\FeyiA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "test_CRF = CRF_Manager(gaz, preprocess)\n",
        "test_CRF.predict_corpus()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['toronto', 'calgary']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"I'm leaving for Toronto tomorrow, I'll be sure to go into Calgary too\"\n",
        "test_CRF.new_prediction(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BI LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\FeyiA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
            "  trackable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weights loaded successfully.\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\FeyiA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Base Scores\n",
            "Accuracy: 0.9890777043320378\n",
            "Precision: 0.9903665888851142\n",
            "Recall: 0.9890777043320378\n",
            "F1 Score: 0.9895388029513108\n",
            "--------------------------------------------------\n",
            "Relevant Scores: Labels of Interest: B-LOC and I-LOC\n",
            "Accuracy: 0.9219474497681608\n",
            "Precision: 0.9830343599073025\n",
            "Recall: 0.9219474497681608\n",
            "F1 Score: 0.9514484837074295\n",
            "--------------------------------------------------\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.82      0.92      0.87       939\n",
            "       I-LOC       0.74      0.92      0.82       355\n",
            "           O       1.00      0.99      0.99     33955\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     35249\n",
            "   macro avg       0.85      0.94      0.89     35249\n",
            "weighted avg       0.99      0.99      0.99     35249\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\FeyiA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "test_BILSTM = BI_LSTM_Manager(gaz, preprocess)\n",
        "test_BILSTM.predict_corpus()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['toronto', 'calgary']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"I'm leaving for Toronto tomorrow, I'll be sure to go into Calgary too\"\n",
        "test_BILSTM.new_prediction(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SVM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weights loaded successfully.\n",
            "--------------------------------------------------\n",
            "Base Scores\n",
            "Accuracy: 0.996176834850035\n",
            "Precision: 0.9961753389769372\n",
            "Recall: 0.996176834850035\n",
            "F1 Score: 0.9961678439607572\n",
            "--------------------------------------------------\n",
            "Relevant Scores: Labels of Interest: B-LOC and I-LOC\n",
            "Accuracy: 0.9400584795321637\n",
            "Precision: 0.9953923269712742\n",
            "Recall: 0.9400584795321637\n",
            "F1 Score: 0.9668993795265762\n",
            "--------------------------------------------------\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.96      0.93      0.95       478\n",
            "       I-LOC       0.97      0.93      0.95       206\n",
            "           O       1.00      1.00      1.00     17887\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     18571\n",
            "   macro avg       0.98      0.95      0.96     18571\n",
            "weighted avg       1.00      1.00      1.00     18571\n",
            " samples avg       1.00      1.00      1.00     18571\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\FeyiA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\FeyiA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "test_SVM = SVM_Manager(gaz, preprocess)\n",
        "test_SVM.predict_corpus()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['toronto', 'calgary']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"I'm leaving for Toronto tomorrow, I'll be sure to go into Calgary too\"\n",
        "test_SVM.new_prediction(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weights loaded successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 1/1 [03:27<00:00, 207.91s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.01\n",
            "Accuracy: 0.9974201749794361\n",
            "Relevant Accuracy: 0.9937733499377335\n",
            "--------------------------------------------------\n",
            "Base Scores\n",
            "Accuracy: 0.9974201749794361\n",
            "Precision: 0.9975015088583858\n",
            "Recall: 0.9974201749794361\n",
            "F1 Score: 0.9974420204073391\n",
            "\n",
            "Relevant Scores: Labels of Interest: B-LOC and I-LOC\n",
            "Accuracy: 0.9937733499377335\n",
            "Precision: 1.0\n",
            "Recall: 0.9937733499377335\n",
            "F1 Score: 0.9968751270273566\n",
            "--------------------------------------------------\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.97      0.99      0.98      1353\n",
            "       I-LOC       0.93      1.00      0.96       253\n",
            "           O       1.00      1.00      1.00     25140\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     26746\n",
            "   macro avg       0.97      1.00      0.98     26746\n",
            "weighted avg       1.00      1.00      1.00     26746\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_BERT = BERT_Manager(gaz, preprocess)\n",
        "test_BERT.predict_corpus()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Prediction: 100%|██████████| 1/1 [00:04<00:00,  4.10s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['toronto', 'calgary']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"I'm leaving for Toronto tomorrow, I'll be sure to go into Calgary too\"\n",
        "test_BERT.new_prediction(text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9BGHEgZtXcr7",
        "xvNyvr74cwiN",
        "qqf-rQo6cwuI",
        "9n7eaMKUcw2a"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
